[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index 2.html",
    "href": "index 2.html",
    "title": "Homework 2 - Scrapy",
    "section": "",
    "text": "Introduction\nhttps://andrewshan214.github.io/PIC16B/posts/Homework%20#2%20-%20Scrapy/index.ipynb\nIn this blog post, I will be giving a tutorial on how to write a spider in scrapy to scrape information from a movie database. More specifically, I will be demonstrating using Christopher Nolan’s “The Dark Knight”, one of my favorite movies. Using the data that I scrape, I will create a chart to suggest movies based on the actors in “The Dark Knight”.\n\n\nWriting the movie database parse() function\nFirst we write the initial parse() function, shown below:\n\ndef parse(self, response):\n        cast_crew_url = f\"https://www.themoviedb.org/movie/155-the-dark-knight/cast\"\n        yield scrapy.Request(cast_crew_url, callback=self.parse_full_credits)\n\nThis method works by saving the url of the full cast and crew page of the movie website. I use scrapy’s built in functions to go into this website and call a second parse function that will save all of the nanmes of those that acted in the movie. The implementation of the second parse function is below.\n\n\nparse_full_credits function implementation\n\ndef parse_full_credits(self, response):\n        for cast_member in response.css(\"ol.people.credits li\"):\n            actor_url = cast_member.css('a::attr(href)').get()\n\n            if actor_url:\n                yield scrapy.Request(url=response.urljoin(actor_url), callback=self.parse_actor_page)\n\nFirstly, I iterated through all of the actors by using the css identifier of only actors by looking at the html code in the movie cast website. While iterating, I saved each actor’s unique page url in a variable. Using that url variable, I used Scrapy’s request function to go into the actor’s page.\nIn this page, I called a third parse function.\n\n\nparse_actor_page function implementation\n\ndef parse_actor_page(self, response):\n        actor_name = response.css('div.title h2.title a::text').get()\n\n        acting_roles = response.css('div.credits_list h3.zero:contains(\"Acting\")')\n        \n        if acting_roles:\n            for acting_role in acting_roles.xpath('./following-sibling::table[@class=\"card credits\"]//table[@class=\"credit_group\"]'):\n                movie_name = acting_role.css('td.role a.tooltip bdi::text').get()\n\n                if movie_name:\n                    yield {\n                        'actor': actor_name,\n                        'movie_or_TV_name': movie_name,\n                    }\n\nI implemented this by first getting the actor’s name by using the css identifier from the website.\nNext, I sorted through only this actor’s acting roles by using the css identifier for acting roles, which was “Zero”. I iterated through all of these acting roles, and got each movie name, and yielded them into a dictionary of the actor’s name and the movies they’ve acted in."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Hello classmates! I’m a third year Mathematics/Economics Major, with a specialization in Computing.\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/Homework 5 - Image Classification/index.html",
    "href": "posts/Homework 5 - Image Classification/index.html",
    "title": "Image Classification Tutorial",
    "section": "",
    "text": "Introduction\nThe url for this blog is: https://andrewshan214.github.io/PIC16B/\nThe url for the github repo is: https://github.com/andrewshan214/PIC16B\nIn this blog post, I will be giving a short tutorial on how to implement an image classification model to distinguish between photos of dogs and cats.\nFirst, we import the proper packages in Python to develop our model. (See below)\n\nimport os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\nimport keras\nfrom keras import utils\nimport tensorflow_datasets as tfds\n\n\n\nCreating the dataset\nBelow is code that is used to create datasets for training, validation, and testing.\n\ntrain_ds, validation_ds, test_ds = tfds.load(\n    \"cats_vs_dogs\",\n    # 40% for training, 10% for validation, and 10% for test (the rest unused)\n    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n    as_supervised=True,  # Include labels\n)\n\nprint(f\"Number of training samples: {train_ds.cardinality()}\")\nprint(f\"Number of validation samples: {validation_ds.cardinality()}\")\nprint(f\"Number of test samples: {test_ds.cardinality()}\")\n\nNumber of training samples: 9305\nNumber of validation samples: 2326\nNumber of test samples: 2326\n\n\n\n\nResizing the images\nBelow, we write code to resize all of the images to a standard size of (150, 150), as well as to rapidly read data by altering the batch_size to 64.\n\nresize_fn = keras.layers.Resizing(150, 150)\n\ntrain_ds = train_ds.map(lambda x, y: (resize_fn(x), y))\nvalidation_ds = validation_ds.map(lambda x, y: (resize_fn(x), y))\ntest_ds = test_ds.map(lambda x, y: (resize_fn(x), y))\n\n\nfrom tensorflow import data as tf_data\nbatch_size = 64\n\ntrain_ds = train_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\nvalidation_ds = validation_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\ntest_ds = test_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\n\n\n\nVisualizing the dataset\nBelow, I have implemented a function called visualize_dataset) that creates two lists, and adds 3 random images of dogs and cats in each, respectively. i use the “take” method to get images of each animal from the dataset to fill the lists.\nThen I iterate through the lists to create a plot that displays 3 random cats in the first row and 3 random dogs in the second row, using the pyplot library.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef visualize_dataset(dataset, num_samples=3, title=\"\"):\n    \n    plt.figure(figsize=(15, 6))\n\n    # initialize empty sets for each animal\n    cat_images, dog_images = [], []\n    #for loop to iterate through each image in the dataset\n    for images, labels in dataset.take(1):\n        for image, label in zip(images, labels):\n            if label == 0:\n                cat_images.append(image.numpy())\n            else:\n                dog_images.append(image.numpy())\n\n    for i in range(num_samples):\n        # Plot cat images in the first row\n        plt.subplot(2, num_samples, i + 1)\n        plt.imshow(cat_images[i].astype(\"uint8\"))\n        plt.title(\"Cat\")\n        plt.axis(\"off\")\n\n        # Plot dog images in the second row\n        plt.subplot(2, num_samples, i + num_samples + 1)\n        plt.imshow(dog_images[i].astype(\"uint8\"))\n        plt.title(\"Dog\")\n        plt.axis(\"off\")\n\n    plt.show()\n\n\n\nvisualize_dataset(train_ds, title=\"Random Samples from Training Dataset\")\n\n2024-03-11 15:24:34.212439: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n\n\n\n\n\n\n\n\n\n\n\nChecking Label Frequencies\nBelow, we’ve created an iterator that can go through the dataset, which we’ve used to count the total number of images of both cats and dogs by using a simple for loop.\n\nlabels_iterator= train_ds.unbatch().map(lambda image, label: label).as_numpy_iterator()\n\ncat_count = 0\ndog_count = 0\n\n# Iterate through labels\nfor label in labels_iterator:\n    if label == 0:\n        cat_count += 1\n    elif label == 1:\n        dog_count += 1\n\nprint(\"Number of images with label 0 (cat):\", cat_count)\nprint(\"Number of images with label 1 (dog):\", dog_count)\n\nNumber of images with label 0 (cat): 4637\nNumber of images with label 1 (dog): 4668\n\n\n\n\nCreating model1\nBelow we implemented our first model, which includes different layers to the model. Each layer processes a bit of the input data and produces an output. Each layer consists of a set of neurons that perform specific computation on the input data.\nAfter implementing the layers into model1, we compile and fit the model to evaluate the test and validation accuracy.\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\nmodel1 = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel1.compile(optimizer='adam',\n               loss='binary_crossentropy',\n               metrics=['accuracy'])\n\nhistory = model1.fit(train_ds, \n                     epochs=20, \n                     validation_data=validation_ds)\n\n# history = model1.fit(train_ds.batch(batch_size), \n#                       epochs=20, \n#                       validation_data=validation_ds.batch(batch_size))\n\nEpoch 1/20\n146/146 [==============================] - 399s 3s/step - loss: 8.8767 - accuracy: 0.5283 - val_loss: 0.6919 - val_accuracy: 0.5155\nEpoch 2/20\n146/146 [==============================] - 349s 2s/step - loss: 0.6885 - accuracy: 0.5395 - val_loss: 0.6833 - val_accuracy: 0.5464\nEpoch 3/20\n146/146 [==============================] - 324s 2s/step - loss: 0.6826 - accuracy: 0.5575 - val_loss: 0.6810 - val_accuracy: 0.5559\nEpoch 4/20\n146/146 [==============================] - 343s 2s/step - loss: 0.6745 - accuracy: 0.5702 - val_loss: 0.6919 - val_accuracy: 0.5408\nEpoch 5/20\n146/146 [==============================] - 345s 2s/step - loss: 0.6772 - accuracy: 0.5743 - val_loss: 0.7042 - val_accuracy: 0.5288\nEpoch 6/20\n146/146 [==============================] - 321s 2s/step - loss: 0.6589 - accuracy: 0.5832 - val_loss: 0.7062 - val_accuracy: 0.5322\nEpoch 7/20\n146/146 [==============================] - 328s 2s/step - loss: 0.6491 - accuracy: 0.5918 - val_loss: 0.7230 - val_accuracy: 0.5245\nEpoch 8/20\n146/146 [==============================] - 339s 2s/step - loss: 0.6336 - accuracy: 0.6121 - val_loss: 0.7309 - val_accuracy: 0.5258\nEpoch 9/20\n146/146 [==============================] - 344s 2s/step - loss: 0.6014 - accuracy: 0.6326 - val_loss: 0.8717 - val_accuracy: 0.5404\nEpoch 10/20\n146/146 [==============================] - 343s 2s/step - loss: 0.6273 - accuracy: 0.6451 - val_loss: 0.8127 - val_accuracy: 0.5357\nEpoch 11/20\n146/146 [==============================] - 330s 2s/step - loss: 0.5895 - accuracy: 0.6431 - val_loss: 1.0035 - val_accuracy: 0.5245\nEpoch 12/20\n146/146 [==============================] - 330s 2s/step - loss: 0.5629 - accuracy: 0.6614 - val_loss: 0.8088 - val_accuracy: 0.5279\nEpoch 13/20\n146/146 [==============================] - 328s 2s/step - loss: 0.5538 - accuracy: 0.6700 - val_loss: 0.8364 - val_accuracy: 0.5340\nEpoch 14/20\n146/146 [==============================] - 327s 2s/step - loss: 0.5187 - accuracy: 0.7004 - val_loss: 0.8670 - val_accuracy: 0.5426\nEpoch 15/20\n146/146 [==============================] - 328s 2s/step - loss: 0.5398 - accuracy: 0.6886 - val_loss: 0.9341 - val_accuracy: 0.5421\nEpoch 16/20\n146/146 [==============================] - 335s 2s/step - loss: 0.5129 - accuracy: 0.7042 - val_loss: 0.9088 - val_accuracy: 0.5404\nEpoch 17/20\n146/146 [==============================] - 355s 2s/step - loss: 0.4887 - accuracy: 0.7217 - val_loss: 0.9090 - val_accuracy: 0.5563\nEpoch 18/20\n146/146 [==============================] - 374s 3s/step - loss: 0.4769 - accuracy: 0.7309 - val_loss: 0.9431 - val_accuracy: 0.5533\nEpoch 19/20\n146/146 [==============================] - 371s 3s/step - loss: 0.4518 - accuracy: 0.7566 - val_loss: 0.9338 - val_accuracy: 0.5550\nEpoch 20/20\n146/146 [==============================] - 366s 3s/step - loss: 0.3941 - accuracy: 0.7881 - val_loss: 0.9704 - val_accuracy: 0.5602\n\n\nSome things I experimented with was increasing the model complexity by adding more layers. Additionally, I tried to regularized the data to prevent overfitting.\nThe validation accuracy of my model stabilized between 62% and 63% during training, which is higher than the baseline.\n\n\nVisualizing the model accuracy\nWe use matplotlib.pyplot to visualize the history, as seen below:\n\nfrom matplotlib import pyplot as plt\nplt.plot(history.history[\"accuracy\"])\nplt.gca().set(xlabel=\"epoch\", ylabel=\"training accuracy\")\n\n\n\n\n\n\n\n\n\n\nModel with Data Augmentation\nBy augmenting the data, it allows the model to recognize images, even if they’re rotated or mirrored.\nThe random flip layer is implemented, by randomly mirroring images, and initializing the layer to that.\nSimilarly, the random rotation layer by randomly rotating the images, and training a layer to the random rotations.\nI’ve added before and after photos for the effect of both layers for visual aid. See code and images below.\n\n#random_flip_layer\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n# Load a few sample images\nsample_images = []\nfor image, label in train_ds.take(1):\n    sample_images = image.numpy()[:4]  # Take the first three images\n\n# Normalize pixel values to the range [0, 1]\nsample_images = sample_images.astype(\"float32\") / 255.0\n\n# Create a RandomFlip layer\nrandom_flip_layer = tf.keras.layers.RandomFlip(\"horizontal\")\n\n# Apply RandomFlip to the sample images\naugmented_images = random_flip_layer(sample_images)\n\n# Plot original and augmented images\nplt.figure(figsize=(10, 7))\nfor i in range(0, 3):\n    # Original image\n    plt.subplot(2, 3, i + 1)\n    plt.imshow(sample_images[i])\n    plt.title(\"Original\")\n    plt.axis(\"off\")\n\n    # Augmented image\n    plt.subplot(2, 3, i + 4)\n    plt.imshow(augmented_images[i])\n    plt.title(\"Augmented\")\n    plt.axis(\"off\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\n#RandomRotation layer\n\nsample_images = []\nfor image, label in train_ds.take(1):\n    sample_images = image.numpy()[:3]  # Take the first three images\n\n# Normalize pixel values to the range [0, 1]\nsample_images = sample_images.astype(\"float32\") / 255.0\n\n# Create a RandomRotation layer\nrandom_rotation_layer = tf.keras.layers.RandomRotation(factor=0.5)\n\n# Apply RandomRotation to the sample images\naugmented_images = random_rotation_layer(sample_images)\n\n# Plot original and augmented images\nplt.figure(figsize=(10, 7))\nfor i in range(0, 3):\n    # Original image\n    plt.subplot(2, 3, i + 1)\n    plt.imshow(sample_images[i])\n    plt.title(\"Original\")\n    plt.axis(\"off\")\n\n    # Augmented image\n    plt.subplot(2, 3, i + 4)\n    plt.imshow(augmented_images[i])\n    plt.title(\"Augmented\")\n    plt.axis(\"off\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nModel 2\nAfter creating those two layers above, we include them in the second model (in addition to all the other layers from model1) to hopefully find a more accurate model. See code below.\n\n#creating model2 with augmentation layers\n\nmodel2 = tf.keras.Sequential([\n    tf.keras.layers.RandomFlip(\"horizontal\"),\n    tf.keras.layers.RandomRotation(factor=0.2),\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n# Compile model2\nmodel2.compile(optimizer='adam',\n               loss='binary_crossentropy',\n               metrics=['accuracy'])\n\n# Train model2\nhistory2 = model2.fit(train_ds, \n                      epochs=20, \n                      validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 64s 424ms/step - loss: 14.0102 - accuracy: 0.5652 - val_loss: 0.6646 - val_accuracy: 0.6028\nEpoch 2/20\n146/146 [==============================] - 73s 499ms/step - loss: 0.6700 - accuracy: 0.5996 - val_loss: 0.6511 - val_accuracy: 0.6277\nEpoch 3/20\n146/146 [==============================] - 73s 500ms/step - loss: 0.6526 - accuracy: 0.6272 - val_loss: 0.6448 - val_accuracy: 0.6427\nEpoch 4/20\n146/146 [==============================] - 74s 507ms/step - loss: 0.6405 - accuracy: 0.6420 - val_loss: 0.6272 - val_accuracy: 0.6711\nEpoch 5/20\n146/146 [==============================] - 73s 501ms/step - loss: 0.6301 - accuracy: 0.6495 - val_loss: 0.6133 - val_accuracy: 0.6883\nEpoch 6/20\n146/146 [==============================] - 74s 510ms/step - loss: 0.6266 - accuracy: 0.6462 - val_loss: 0.6142 - val_accuracy: 0.6776\nEpoch 7/20\n146/146 [==============================] - 77s 528ms/step - loss: 0.6211 - accuracy: 0.6627 - val_loss: 0.6052 - val_accuracy: 0.6879\nEpoch 8/20\n146/146 [==============================] - 77s 526ms/step - loss: 0.6068 - accuracy: 0.6754 - val_loss: 0.5935 - val_accuracy: 0.7064\nEpoch 9/20\n146/146 [==============================] - 77s 528ms/step - loss: 0.6003 - accuracy: 0.6833 - val_loss: 0.5868 - val_accuracy: 0.6935\nEpoch 10/20\n146/146 [==============================] - 74s 505ms/step - loss: 0.5975 - accuracy: 0.6876 - val_loss: 0.5812 - val_accuracy: 0.6900\nEpoch 11/20\n146/146 [==============================] - 74s 508ms/step - loss: 0.5929 - accuracy: 0.6910 - val_loss: 0.5637 - val_accuracy: 0.7034\nEpoch 12/20\n146/146 [==============================] - 72s 496ms/step - loss: 0.5835 - accuracy: 0.6937 - val_loss: 0.5592 - val_accuracy: 0.7240\nEpoch 13/20\n146/146 [==============================] - 72s 492ms/step - loss: 0.5918 - accuracy: 0.6905 - val_loss: 0.5864 - val_accuracy: 0.6943\nEpoch 14/20\n146/146 [==============================] - 75s 510ms/step - loss: 0.5700 - accuracy: 0.7091 - val_loss: 0.5613 - val_accuracy: 0.7283\nEpoch 15/20\n146/146 [==============================] - 70s 479ms/step - loss: 0.5692 - accuracy: 0.7075 - val_loss: 0.5369 - val_accuracy: 0.7369\nEpoch 16/20\n146/146 [==============================] - 72s 494ms/step - loss: 0.5681 - accuracy: 0.7055 - val_loss: 0.5673 - val_accuracy: 0.7193\nEpoch 17/20\n146/146 [==============================] - 70s 479ms/step - loss: 0.5588 - accuracy: 0.7099 - val_loss: 0.5414 - val_accuracy: 0.7334\nEpoch 18/20\n146/146 [==============================] - 71s 485ms/step - loss: 0.5510 - accuracy: 0.7207 - val_loss: 0.5134 - val_accuracy: 0.7459\nEpoch 19/20\n146/146 [==============================] - 74s 505ms/step - loss: 0.5360 - accuracy: 0.7313 - val_loss: 0.5164 - val_accuracy: 0.7567\nEpoch 20/20\n146/146 [==============================] - 73s 497ms/step - loss: 0.5382 - accuracy: 0.7312 - val_loss: 0.5260 - val_accuracy: 0.7468\n\n\nThe accuracy of my model stabilized between 64% and 65% during training, which is a bit higher than in model1, and still higher than 60%.\nIn model2, if the accuracy stabilized around 64% to 65% during training and the validation accuracy closely tracked the training accuracy without diverging significantly, it indicates that the model may not be overfitting. Signs of overfitting include a large gap between training and validation accuracy or when the validation accuracy starts decreasing while the training accuracy continues to increase.\nAs with model1, we will visualize our results.\n\nplt.plot(history2.history[\"accuracy\"])\nplt.gca().set(xlabel=\"epoch\", ylabel=\"training accuracy\")\n\n\n\n\n\n\n\n\n\n\nModel 3\nWe implemented model 3 hoping to make training the model faster by implemented a preprocessor layer that would handle the scaling of the RGB values prior to the training process. This allows the computer to focus more energy on handling actual signal in the data and less energy having the weights adjust to the data scale.\n\ni = keras.Input(shape=(150, 150, 3))\n# The pixel values have the range of (0, 255), but many models will work better if rescaled to (-1, 1.)\n# outputs: `(inputs * scale) + offset`\nscale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\nx = scale_layer(i)\npreprocessor = keras.Model(inputs = [i], outputs = [x])\n\nmodel3 = tf.keras.Sequential([\n    preprocessor,\n    tf.keras.layers.RandomFlip(\"horizontal\"),\n    tf.keras.layers.RandomRotation(factor=0.2),\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n# Compile model3\nmodel3.compile(optimizer='adam',\n               loss='binary_crossentropy',\n               metrics=['accuracy'])\n\nhistory3 = model3.fit(train_ds, \n                      epochs=20,  # Increase the number of epochs\n                      validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 67s 456ms/step - loss: 0.7266 - accuracy: 0.5728 - val_loss: 0.6305 - val_accuracy: 0.6664\nEpoch 2/20\n146/146 [==============================] - 69s 470ms/step - loss: 0.6211 - accuracy: 0.6585 - val_loss: 0.5609 - val_accuracy: 0.7223\nEpoch 3/20\n146/146 [==============================] - 66s 451ms/step - loss: 0.5794 - accuracy: 0.6969 - val_loss: 0.5290 - val_accuracy: 0.7442\nEpoch 4/20\n146/146 [==============================] - 65s 443ms/step - loss: 0.5574 - accuracy: 0.7180 - val_loss: 0.5131 - val_accuracy: 0.7528\nEpoch 5/20\n146/146 [==============================] - 66s 449ms/step - loss: 0.5419 - accuracy: 0.7316 - val_loss: 0.5037 - val_accuracy: 0.7571\nEpoch 6/20\n146/146 [==============================] - 65s 448ms/step - loss: 0.5307 - accuracy: 0.7329 - val_loss: 0.4927 - val_accuracy: 0.7623\nEpoch 7/20\n146/146 [==============================] - 72s 494ms/step - loss: 0.5173 - accuracy: 0.7459 - val_loss: 0.4771 - val_accuracy: 0.7678\nEpoch 8/20\n146/146 [==============================] - 69s 471ms/step - loss: 0.5063 - accuracy: 0.7536 - val_loss: 0.4839 - val_accuracy: 0.7704\nEpoch 9/20\n146/146 [==============================] - 67s 459ms/step - loss: 0.5076 - accuracy: 0.7545 - val_loss: 0.4746 - val_accuracy: 0.7760\nEpoch 10/20\n146/146 [==============================] - 64s 440ms/step - loss: 0.4912 - accuracy: 0.7695 - val_loss: 0.4892 - val_accuracy: 0.7713\nEpoch 11/20\n146/146 [==============================] - 65s 447ms/step - loss: 0.4854 - accuracy: 0.7668 - val_loss: 0.4462 - val_accuracy: 0.7954\nEpoch 12/20\n146/146 [==============================] - 64s 440ms/step - loss: 0.4799 - accuracy: 0.7710 - val_loss: 0.4689 - val_accuracy: 0.7846\nEpoch 13/20\n146/146 [==============================] - 66s 455ms/step - loss: 0.4724 - accuracy: 0.7740 - val_loss: 0.4539 - val_accuracy: 0.7975\nEpoch 14/20\n146/146 [==============================] - 65s 443ms/step - loss: 0.4642 - accuracy: 0.7810 - val_loss: 0.4534 - val_accuracy: 0.7962\nEpoch 15/20\n146/146 [==============================] - 65s 445ms/step - loss: 0.4613 - accuracy: 0.7825 - val_loss: 0.4515 - val_accuracy: 0.8014\nEpoch 16/20\n146/146 [==============================] - 64s 435ms/step - loss: 0.4512 - accuracy: 0.7828 - val_loss: 0.4683 - val_accuracy: 0.7829\nEpoch 17/20\n146/146 [==============================] - 64s 440ms/step - loss: 0.4552 - accuracy: 0.7875 - val_loss: 0.4413 - val_accuracy: 0.7979\nEpoch 18/20\n146/146 [==============================] - 66s 452ms/step - loss: 0.4485 - accuracy: 0.7940 - val_loss: 0.4312 - val_accuracy: 0.8083\nEpoch 19/20\n146/146 [==============================] - 71s 483ms/step - loss: 0.4311 - accuracy: 0.8032 - val_loss: 0.4197 - val_accuracy: 0.8156\nEpoch 20/20\n146/146 [==============================] - 69s 473ms/step - loss: 0.4303 - accuracy: 0.8077 - val_loss: 0.4345 - val_accuracy: 0.8113\n\n\nThe validation accuracy stabilized between 80% and 82% during training This is much higher than the val_accuracy of model1, which was ~60%.\nSince there is not a significant gap between the training and validation accuracy, it suggests that model3 is not overfitting the data.\n\n\nVisualizing model3 results\nWe will once again visualize these results.\n\nplt.plot(history3.history[\"accuracy\"])\nplt.gca().set(xlabel=\"epoch\", ylabel=\"training accuracy\")\n\n\n\n\n\n\n\n\n\n\nTransfer Learning\nTransfer learning is essentially accessing a pre-existing base model and incorporating it into our own model. The first few lines of the code below is downloading MobileNetV3Large, which will serve as our base model. We create a base_model_layer that we implement into our model4, which is constructed in the same manner as the previous 3 models.\n\nIMG_SHAPE = (150, 150, 3)\nbase_model = keras.applications.MobileNetV3Large(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights=None)\nweights_path = '/Users/andrewhan/PIC16B/posts/Homework 5 - Image Classification/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5'\nbase_model.load_weights(weights_path)\n\nbase_model.trainable = False\n\ni = keras.Input(shape=IMG_SHAPE)\nx = base_model(i, training = False)\nbase_model_layer = keras.Model(inputs = i, outputs = x)\n\ndata_augmentation = tf.keras.Sequential([\n    tf.keras.layers.RandomFlip(\"horizontal\"),\n    tf.keras.layers.RandomRotation(factor=0.2)\n])\n\nmodel4 = tf.keras.Sequential([\n    data_augmentation,\n    base_model,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(2, activation='softmax')  \n])\n\nmodel4.compile(optimizer='adam',\n               loss='sparse_categorical_crossentropy',\n               metrics=['accuracy'])\n\nhistory4 = model4.fit(train_ds, \n                      epochs=20,  # Increase the number of epochs\n                      validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 41s 262ms/step - loss: 0.2380 - accuracy: 0.8972 - val_loss: 0.0899 - val_accuracy: 0.9656\nEpoch 2/20\n146/146 [==============================] - 37s 253ms/step - loss: 0.1325 - accuracy: 0.9462 - val_loss: 0.0767 - val_accuracy: 0.9725\nEpoch 3/20\n146/146 [==============================] - 37s 256ms/step - loss: 0.1177 - accuracy: 0.9525 - val_loss: 0.0814 - val_accuracy: 0.9699\nEpoch 4/20\n146/146 [==============================] - 38s 259ms/step - loss: 0.1106 - accuracy: 0.9550 - val_loss: 0.0710 - val_accuracy: 0.9759\nEpoch 5/20\n146/146 [==============================] - 40s 273ms/step - loss: 0.1081 - accuracy: 0.9570 - val_loss: 0.0714 - val_accuracy: 0.9755\nEpoch 6/20\n146/146 [==============================] - 41s 280ms/step - loss: 0.1108 - accuracy: 0.9567 - val_loss: 0.0782 - val_accuracy: 0.9733\nEpoch 7/20\n146/146 [==============================] - 51s 350ms/step - loss: 0.1054 - accuracy: 0.9570 - val_loss: 0.0728 - val_accuracy: 0.9738\nEpoch 8/20\n146/146 [==============================] - 45s 308ms/step - loss: 0.1033 - accuracy: 0.9595 - val_loss: 0.0708 - val_accuracy: 0.9746\nEpoch 9/20\n146/146 [==============================] - 42s 287ms/step - loss: 0.0892 - accuracy: 0.9632 - val_loss: 0.0670 - val_accuracy: 0.9772\nEpoch 10/20\n146/146 [==============================] - 41s 281ms/step - loss: 0.0995 - accuracy: 0.9594 - val_loss: 0.0642 - val_accuracy: 0.9781\nEpoch 11/20\n146/146 [==============================] - 41s 279ms/step - loss: 0.0935 - accuracy: 0.9623 - val_loss: 0.0660 - val_accuracy: 0.9768\nEpoch 12/20\n146/146 [==============================] - 41s 278ms/step - loss: 0.0931 - accuracy: 0.9637 - val_loss: 0.0701 - val_accuracy: 0.9755\nEpoch 13/20\n146/146 [==============================] - 42s 284ms/step - loss: 0.0975 - accuracy: 0.9611 - val_loss: 0.0644 - val_accuracy: 0.9772\nEpoch 14/20\n146/146 [==============================] - 40s 274ms/step - loss: 0.0879 - accuracy: 0.9657 - val_loss: 0.0729 - val_accuracy: 0.9738\nEpoch 15/20\n146/146 [==============================] - 41s 279ms/step - loss: 0.0938 - accuracy: 0.9626 - val_loss: 0.0666 - val_accuracy: 0.9772\nEpoch 16/20\n146/146 [==============================] - 41s 280ms/step - loss: 0.0884 - accuracy: 0.9661 - val_loss: 0.0727 - val_accuracy: 0.9738\nEpoch 17/20\n146/146 [==============================] - 41s 282ms/step - loss: 0.0954 - accuracy: 0.9607 - val_loss: 0.0687 - val_accuracy: 0.9768\nEpoch 18/20\n146/146 [==============================] - 40s 274ms/step - loss: 0.0920 - accuracy: 0.9622 - val_loss: 0.0729 - val_accuracy: 0.9738\nEpoch 19/20\n146/146 [==============================] - 40s 272ms/step - loss: 0.0941 - accuracy: 0.9629 - val_loss: 0.0711 - val_accuracy: 0.9755\nEpoch 20/20\n146/146 [==============================] - 41s 277ms/step - loss: 0.0918 - accuracy: 0.9612 - val_loss: 0.0701 - val_accuracy: 0.9764\n\n\nThe model4 validation accuracy stabilzed between 97% and 98%, which is greater than the required 93% This val_accuracy is also much higher than from model1, which was around 60%.\nThere does not seem to be any overfitting as there is not much difference between the test and validation accuracy.\n\n\nVisualizing the results\n\nplt.plot(history4.history[\"accuracy\"])\nplt.gca().set(xlabel=\"epoch\", ylabel=\"training accuracy\")\n\n\n\n\n\n\n\n\n\n\nScore on Test Data\nThis code below will evaluate the accuracy of model4, which is the most performant model of the four. This will evaluate the unseen test dataset and print the value it returns.\n\ntest_loss, test_accuracy = model4.evaluate(test_ds)\n\n# Print the test accuracy\nprint(f'Test accuracy: {test_accuracy}')\n\n37/37 [==============================] - 8s 211ms/step - loss: 0.0784 - accuracy: 0.9742\nTest accuracy: 0.9742046594619751\n\n\nThe test accuracy was over 97%, so we can see that the model works well. This suggests that the model has effectively learned to distinguish between cats and dogs in the test dataset.\n\n\nConclusion\nIn conclusion, we can see that adding more layers (or more information for the model to account for), the more accurate the model will be at recognizing dogs and cats. As we added more layers to our models, we received higher marks for the validation accuracy in each model."
  },
  {
    "objectID": "posts/Palmer Penguins/index.html",
    "href": "posts/Palmer Penguins/index.html",
    "title": "Palmer Penguins Tutorial",
    "section": "",
    "text": "Blog Post URL https://andrewshan214.github.io/PIC16B/posts/Palmer%20Penguins/\n\nIntroduction\nIn this blog post, I will be giving a short tutorial on how to make a simple data visualization of the “Palmer Penguins” data set. More specifically, I will be showing a simple and informative visualization as a scatter plot to visualize the relationship between penguin culmen length and culmen depth.\nFirst, we load the necessary packages and data, as shown below.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndata = \"/Users/andrewhan/PIC16B/posts/Palmer Penguins/palmer_penguins.csv\"\npenguins = pd.read_csv(data)\n\n\n\nFiltering/cleaning the data\nNext, we will filter our data set to drop any entries with NaN values for their culmen length and/or depth.\nUsing that filtered data, we will group the data based on those categories. Then we will plot the data using the matplotlib package. Using key words, we can choose the type of chart we want, as well as the colors. In this case, I went with a scatter plot with blue dots.\nAfter adding the titles and labels, we can display our data visualization!\n\npenguins_filtered = penguins.dropna(subset = ['Culmen Length (mm)', 'Culmen Depth (mm)'])\n\nplt.figure(figsize=(10, 6))\nplt.scatter(penguins['Culmen Length (mm)'], penguins['Culmen Depth (mm)'], c='blue', alpha=0.7)\nplt.title('Scatter Plot of Culmen Length vs Culmen Depth')\nplt.xlabel('Culmen Length (mm)')\nplt.ylabel('Culmen Depth (mm)')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nConclusion\nAs we can see, there is scatter plot with all of our data points (penguins) plotted with their respective culmen length and depth. It seems that there is no identifiable trend between their length and depth measurements as there are many penguins with both proportionally larger culmen lengths and culmen depths."
  },
  {
    "objectID": "posts/Homework3-Message_Bank/index.html",
    "href": "posts/Homework3-Message_Bank/index.html",
    "title": "Message bank Tutorial",
    "section": "",
    "text": "Introduction\nThe url for this blog is: https://andrewshan214.github.io/PIC16B/\nThe url for the github repo is: https://github.com/andrewshan214/PIC16B\nIn this blog post, I will be giving a short tutorial on how to make a simple message bank using Python’s Flask library, as well as incorporating HTML and CSS files to develop a webpage\nFirst, we create the necessary files. To start we will create our app.py file, which will be a Python script file that will be running the Flask library tasks. Please see below.\n\nfrom flask import Flask, render_template, request\nfrom flask import redirect, url_for, abort\nfrom flask import g\nimport sqlite3\n\napp = Flask(__name__)\n\n\n\nGoing through app.py file\nAlong with importing the necessary libraries, we must define a few functions and databases for our message bank. Please see the comments above each function to understand what each function is doing in the context of the webpage.\n\n# Create a sqlite3 database to handle all of the submitted messages\nDATABASE = 'messages_db.sqlite'\n\n# This function checks for the existence of a message_db in the global 'g' object. It then closes the database connection if it sees its existence.\n@app.teardown_appcontext\ndef close_db(error):\n    if hasattr(g, 'message_db'):\n        g.message_db.close()\n\n@app.route('/') # @app.route essentially tells the code what the end of the url of this particular page would be. \n# Because this is the base 'Home' page, we use a simple '/' to conclude the url.\ndef base():\n    #Uses Flask's render_template function to render the base.html file\n    return render_template('base.html')\n\n\n\nConnection between app.py and each page’s html file.\nAfter defining a base() function, we must accompany it with an html file to tell the website what to display on this page. See below for the code for base.html.\n\n&lt;!doctype html&gt;\n&lt;link rel=\"stylesheet\" href=\"{{ url_for('static', filename='style.css') }}\"&gt;\n&lt;title&gt;{% block title %}{% endblock %} - PIC16B Website&lt;/title&gt;\n&lt;nav&gt;\n    &lt;h1&gt;PIC16B Message Bank!&lt;/h1&gt;\n    &lt;ul&gt;\n        &lt;li&gt;&lt;a href=\"{{ url_for('base') }}\"&gt;Main page&lt;/a&gt;&lt;/li&gt;\n        &lt;li&gt;&lt;a href=\"{{ url_for('submit_message')}}\"&gt;Submit Message&lt;/a&gt;&lt;/li&gt;\n        &lt;li&gt;&lt;a href=\"{{ url_for('render_view_template') }}\"&gt;View Messages&lt;/a&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n&lt;nav&gt;\n&lt;section class=\"content\"&gt;\n    &lt;header&gt;\n    {% block header %}{% endblock %}\n    &lt;/header&gt;\n    {% block content %}{% endblock %}\n&lt;/section&gt;\n\n\n\nHTML explanation\nHTML lines begin with ‘&lt; keyword&gt;’ to indicate the purpose of each line. The line &lt; link rel=“stylesheet” href=“{{ url_for(‘static’, filename=‘style.css’) }}”&gt; indicates to the program to link the entire page to the style.css sheet in the directory.\n&lt; nav&gt; initializes a navigation page, with the header PIC16B Message Bank! using &lt; h1 &gt; keyword. &lt; ul&gt; initializes an unordered list, while &lt; li&gt; is each individual list entry.\n&lt; section&gt; creates a new section, while each {% block} where the content of the page will be added.\n\n\nbase.html\nWhat this code is doing is both serving as a base for additional html files, as well as formatting the base page. It lays out a page title, as well as navigation functionality to visit other pages. We use Flask’s render_template function a lot in this program to render the accompanying HTML file.\nSee below for the app.py function that renders the message submission page, as well as the accompanying submit.html file.\n\n# Like before, we use @app.route. \n#However, now we must define the methods to ensure that user submission is possible by adding methods=['GET, POST']\n\n#function to submit messages to the database\n@app.route('/submit/', methods=['GET', 'POST'])\ndef submit_message():\n    #different methods for diff request methods\n    if request.method == 'GET':\n        #if 'GET' just render the template\n        return render_template('submit.html')\n    \n    else:\n        try:\n            handle, message = insert_message(request)\n            #render the template with a thank you note\n            return render_template('submit.html', thank_you = True, message = message, handle = handle)\n        except:\n            return render_template('submit.html', error=True)\n\n\n{% extends \"base.html\" %} \n\n{% block header %}\n  &lt;h1&gt;{% block title %}Submit Message{% endblock %}&lt;/h1&gt;\n{% endblock %}\n\n{% block content %}\n    &lt;form action=\"/submit\" method=\"post\"&gt;\n        &lt;label for=\"message\"&gt;Message:&lt;/label&gt;&lt;br&gt;\n        &lt;input type=\"text\" id=\"message\" name=\"message\"&gt;&lt;br&gt;\n        &lt;label for=\"name\"&gt;Name:&lt;/label&gt;&lt;br&gt;\n        &lt;input type=\"text\" id=\"name\" name=\"name\"&gt;&lt;br&gt;\n        &lt;input type=\"submit\" value=\"Submit\"&gt;\n    &lt;/form&gt;\n{% endblock %}\n\n\n\nHTML explanation\nWe extend base.html to adopt the style elements from style.css. We create a block titled ‘Submit Message’ to create a header for the page.\nAdditionally, we create a new block with a form element to allow the website to take user input in the form of messages and handles. I create multiple input boxes to allow the user to input both the message and their name, as well as a button to submit (which calls the submit_message function)\n\n\nMessage Submission Page\nThis page is run by the function submit_message(), which essentially receives a message from the user and renders the submit.html page. The submit.html file “extends” the base.html file, which essentially means that many components, like the style.css, is automatically transferred from the base.html file to submit.html. See below for a screenshot of this page.\n\n\n\nMessageSubmission\n\n\n\n\nDatabase Management\nSee below for the code for inserting a message into the SQL message database.\n\n@app.route('/getmsg/', methods=['GET'])\ndef get_message_db():\n\n    #try to retrieve database connection from global g object\n    try:\n        db = g.message_db\n    except AttributeError:\n        #if no database connection, connect to the database and call query to create a table called messages\n        db = g.message_db = sqlite3.connect(DATABASE)\n        db.execute('''\n            CREATE TABLE IF NOT EXISTS messages (\n                id INTEGER PRIMARY KEY,\n                handle TEXT,\n                message TEXT\n            )\n        ''')\n    return db\n\n@app.route('/insert_msg/', methods=['POST'])\ndef insert_message(request):\n    # get message and handle from request\n    try:\n        # access the user input from the HTML webpage\n        message = request.form['message']\n        handle = request.form['name']\n\n        #connect to the SQL Database\n        db = get_message_db()\n        cursor = db.cursor()\n        #execute query to insert the user input into the databse\n        cursor.execute(\"INSERT INTO messages (handle, message) VALUES (?, ?)\", (handle, message))\n        db.commit()\n\n        #return a redirection back to the /submit page of the website\n        return redirect('/submit/')\n    \n    #exception if an error occurs\n    except Exception as e:\n        return render_template('submit.html', error=True)\n\n\n\ninsert_message(request)\nWhat this function does is connect to the message database and inserts the user-inputted message into the database so that it can be displayed in the message viewing page. It connects to the database using sqlite3, and executes the query, which inserts a message into the database table.\nSee below for how the message viewing page is run.\n\n\nRandom Messages Page\n\n#function to return a random message from the db\n@app.route('/random_messages/&lt;int:n&gt;')\ndef random_message(n):\n    #connect to the SQL database\n    db = get_message_db()\n    cursor = db.cursor()\n    #run query to select a random list of messages\n    cursor.execute(\"SELECT * FROM messages ORDER BY RANDOM() LIMIT ?\", (n,))\n    #initialize messages to be all the random messages from the above query\n    messages = cursor.fetchall()\n    #render the appropriate page with those messages\n    return render_template('view.html', messages=messages)\n\n#renders the random messages page\n@app.route('/random_messages/')\ndef render_view_template():\n    #display the first 5 messages\n    messages = random_message(5)\n\n    return render_template('view.html', messages = messages)\n\nThese functions connect to the message database, executes a query to randomly select a message, to return and render a list of previously inputted, randomly selected messages to the user. See below for the view.html file.\n\n{% extends \"base.html\" %}\n\n{% block content %}\n    &lt;h2&gt;Random Messages&lt;/h2&gt;\n    &lt;ul&gt;\n        {% for message in messages %}\n            &lt;li&gt;\n                &lt;strong&gt;{{ message.handle }}&lt;/strong&gt; - {{ message.message }}\n            &lt;/li&gt;\n        {% endfor %}\n    &lt;/ul&gt;\n{% endblock %}\n\n\n\nHTML explanation\nBy extending “base.html”, we can adopt all of the style elements from base.html and style.css to all pages in the website.\nAgain we create a block with the header “Random Messages”, which displays an unordered list of message handles and messages using a for loop.\n\n\nview.html\nThis code also “extends” base.html. This html code is much simpler as it simply lists the previous messages, and doesn’t need to receive any information from the website user. See an example below.\n\n\n\nRandomMessages\n\n\n\n\nstyle.css\nWe have now seen how the website functions on the back-end with the database management and user inputs. However, this must all be presentable. As I mentioned earlier, the base.html file is accompanies by a style.css file. See below for the css code.\n\n/* Import a custom font from Google Fonts */\n@import url('https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap');\n\n/* Apply the custom font to the entire body */\nbody {\n    font-family: 'Roboto', sans-serif;\n    background-color: #f0f0f0; /* Light gray background */\n    color: #333; /* Dark gray text */\n}\n\n/* Style the navigation bar */\nnav {\n    background-color: #333; /* Dark background color */\n    color: white; /* White text */\n    padding: 10px;\n}\n\n/* Style navigation links */\nnav a {\n    color: white; /* White text */\n    text-decoration: none; /* Remove underline */\n    margin-right: 10px; /* Add some margin between links */\n}\n\n/* Style the header section */\nheader {\n    background-color: #007bff; /* Blue background color */\n    color: white; /* White text */\n    padding: 20px;\n    text-align: center; /* Center align text */\n}\n\n/* Add some margin around the content */\n.content {\n    margin: 20px;\n}\n\n/* Style forms */\nform {\n    margin-bottom: 20px; /* Add margin below forms */\n}\n\n/* Style text inputs and buttons */\ninput[type=\"text\"], button {\n    padding: 10px;\n    margin-right: 10px;\n}\n\n/* Style buttons */\nbutton {\n    background-color: #007bff; /* Blue background color */\n    color: white; /* White text */\n    border: none; /* Remove border */\n    cursor: pointer; /* Change cursor to pointer */\n}\n\n/* Change button color on hover */\nbutton:hover {\n    background-color: #0056b3; /* Darker blue on hover */\n}\n\n/* Style unordered lists */\nul {\n    list-style-type: none; /* Remove bullet points */\n    padding: 0; /* Remove default padding */\n}\n\n/* Add some margin below list items */\nli {\n    margin-bottom: 10px;\n}\n\nThis code goes through many different customizations, such as font type, font size and color, page color, etc. By using certain keyword for each customization, I am able to change how the styling of the HTML will be rendered.\n\n\nConclusion\nAs we can see, there are many different things to account for in web development. Hopefully, this blog post was informational and helpful in developing your next webpage. Thank you!\n\nAndrew Han"
  },
  {
    "objectID": "posts/Homework #2 - Scrapy/index.html",
    "href": "posts/Homework #2 - Scrapy/index.html",
    "title": "Homework 2 - Scrapy",
    "section": "",
    "text": "Introduction\nhttps://andrewshan214.github.io/PIC16B/posts/Homework%20#2%20-%20Scrapy/index.ipynb\nIn this blog post, I will be giving a tutorial on how to write a spider in scrapy to scrape information from a movie database. More specifically, I will be demonstrating using Christopher Nolan’s “The Dark Knight”, one of my favorite movies. Using the data that I scrape, I will create a chart to suggest movies based on the actors in “The Dark Knight”.\n\n\nWriting the movie database parse() function\nFirst we write the initial parse() function, shown below:\n\ndef parse(self, response):\n        cast_crew_url = f\"https://www.themoviedb.org/movie/155-the-dark-knight/cast\"\n        yield scrapy.Request(cast_crew_url, callback=self.parse_full_credits)\n\nThis method works by saving the url of the full cast and crew page of the movie website. I use scrapy’s built in functions to go into this website and call a second parse function that will save all of the nanmes of those that acted in the movie. The implementation of the second parse function is below.\n\n\nparse_full_credits function implementation\n\ndef parse_full_credits(self, response):\n        for cast_member in response.css(\"ol.people.credits li\"):\n            actor_url = cast_member.css('a::attr(href)').get()\n\n            if actor_url:\n                yield scrapy.Request(url=response.urljoin(actor_url), callback=self.parse_actor_page)\n\nFirstly, I iterated through all of the actors by using the css identifier of only actors by looking at the html code in the movie cast website. While iterating, I saved each actor’s unique page url in a variable. Using that url variable, I used Scrapy’s request function to go into the actor’s page.\nIn this page, I called a third parse function.\n\n\nparse_actor_page function implementation\n\ndef parse_actor_page(self, response):\n        actor_name = response.css('div.title h2.title a::text').get()\n\n        acting_roles = response.css('div.credits_list h3.zero:contains(\"Acting\")')\n        \n        if acting_roles:\n            for acting_role in acting_roles.xpath('./following-sibling::table[@class=\"card credits\"]//table[@class=\"credit_group\"]'):\n                movie_name = acting_role.css('td.role a.tooltip bdi::text').get()\n\n                if movie_name:\n                    yield {\n                        'actor': actor_name,\n                        'movie_or_TV_name': movie_name,\n                    }\n\nI implemented this by first getting the actor’s name by using the css identifier from the website.\nNext, I sorted through only this actor’s acting roles by using the css identifier for acting roles, which was “Zero”. I iterated through all of these acting roles, and got each movie name, and yielded them into a dictionary of the actor’s name and the movies they’ve acted in."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PIC16B",
    "section": "",
    "text": "Image Classification Tutorial\n\n\n\n\n\n\nweek 8\n\n\nhomework\n\n\n\n\n\n\n\n\n\nMar 1, 2024\n\n\nAndrew Han\n\n\n\n\n\n\n\n\n\n\n\n\nMessage bank Tutorial\n\n\n\n\n\n\nweek 5\n\n\nhomework\n\n\n\n\n\n\n\n\n\nFeb 21, 2024\n\n\nAndrew Han\n\n\n\n\n\n\n\n\n\n\n\n\nHomework 2 - Scrapy\n\n\n\n\n\n\nweek 5\n\n\nhomework\n\n\n\n\n\n\n\n\n\nFeb 5, 2024\n\n\nAndrew Han\n\n\n\n\n\n\n\n\n\n\n\n\nPalmer Penguins Tutorial\n\n\n\n\n\n\nweek 3\n\n\nhomework\n\n\n\n\n\n\n\n\n\nJan 22, 2024\n\n\nAndrew Han\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nJan 19, 2024\n\n\nAndrew Han\n\n\n\n\n\n\nNo matching items"
  }
]